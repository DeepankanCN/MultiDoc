{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 2800, which is longer than the specified 1000\n",
      "Created a chunk of size 1324, which is longer than the specified 1000\n",
      "Created a chunk of size 1377, which is longer than the specified 1000\n",
      "Created a chunk of size 1023, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x0000016FF35A6B10> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000016FF35C0DD0> temperature=0.5 openai_api_key=SecretStr('**********') openai_proxy=''\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\deepa\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n",
      "c:\\Users\\deepa\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Geeks_For_Geeks` with `{'question': 'Explain LLMS'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m{'query': 'Explain LLMS', 'result': 'Large Language Models (LLMs) are advanced artificial intelligence algorithms that utilize neural network techniques with a large number of parameters to process and understand human languages or text. These models are trained on extensive datasets using self-supervised learning techniques, where they learn intricate patterns and relationships from diverse language data during training. LLMs consist of multiple layers, including feedforward layers, embedding layers, and attention layers, and employ attention mechanisms like self-attention to capture dependencies and relationships in text sequences. LLMs can perform tasks such as text generation, machine translation, summary writing, image generation from texts, machine coding, chatbots, and conversational AI. They are highly efficient in capturing complex entity relationships in text and can generate text using the semantic and syntactic rules of a particular language.'}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `ibm` with `{'question': 'Explain LLMS'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m{'query': 'Explain LLMS', 'result': 'LLMs, or Large Language Models, are a category of foundation models trained on immense amounts of data, enabling them to understand and generate natural language and other types of content for a wide range of tasks. They have become popular due to their ability to perform tasks like content generation, language translation, code writing, summarization, and more. LLMs are a significant breakthrough in NLP and AI, easily accessible through interfaces like GPT-3, GPT-4, BERT, RoBERTa, and others. They are designed to mimic human-like text generation and understanding based on the extensive data they are trained on.'}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `CloudFare` with `{'question': 'Explain LLMS'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m{'query': 'Explain LLMS', 'result': \"LLMs, or Large Language Models, are a type of machine learning model that use deep learning techniques to understand how characters, words, and sentences function together. They are trained on large amounts of data to recognize patterns and relationships within language. LLMs can be further fine-tuned or prompt-tuned for specific tasks, such as generating text in response to prompts or questions, translating languages, or answering queries based on the data they have been trained on. However, it's important to note that the reliability of the information provided by LLMs depends on the quality of the data they have been trained on, and they can sometimes produce inaccurate or fake information. Additionally, LLMs can be vulnerable to security issues and may expose confidential data if not handled properly.\"}\u001b[0m\u001b[32;1m\u001b[1;3mGeeks for Geeks explains Large Language Models (LLMs) as advanced artificial intelligence algorithms that utilize neural network techniques with a large number of parameters to process and understand human languages or text. These models are trained on extensive datasets using self-supervised learning techniques, where they learn intricate patterns and relationships from diverse language data during training. LLMs consist of multiple layers and employ attention mechanisms like self-attention to capture dependencies and relationships in text sequences. They can perform tasks such as text generation, machine translation, summary writing, image generation from texts, machine coding, chatbots, and conversational AI.\n",
      "\n",
      "IBM describes LLMS as foundation models trained on immense amounts of data, enabling them to understand and generate natural language and other types of content for various tasks. They are popular for tasks like content generation, language translation, code writing, summarization, and more. LLMs are accessible through interfaces like GPT-3, GPT-4, BERT, RoBERTa, and others, designed to mimic human-like text generation and understanding based on the extensive data they are trained on.\n",
      "\n",
      "CloudFare explains LLMS as machine learning models that use deep learning techniques to understand how characters, words, and sentences function together. Trained on large amounts of data, LLMs recognize patterns and relationships within language. They can be fine-tuned for specific tasks such as generating text, translating languages, or answering queries based on the data they have been trained on. However, the reliability of the information provided by LLMs depends on the quality of the data they have been trained on, and they can sometimes produce inaccurate or fake information. Additionally, LLMs can be vulnerable to security issues if not handled properly.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'How Geeks for Geeks explained LLms as compare to ibm and cloudfare?', 'output': 'Geeks for Geeks explains Large Language Models (LLMs) as advanced artificial intelligence algorithms that utilize neural network techniques with a large number of parameters to process and understand human languages or text. These models are trained on extensive datasets using self-supervised learning techniques, where they learn intricate patterns and relationships from diverse language data during training. LLMs consist of multiple layers and employ attention mechanisms like self-attention to capture dependencies and relationships in text sequences. They can perform tasks such as text generation, machine translation, summary writing, image generation from texts, machine coding, chatbots, and conversational AI.\\n\\nIBM describes LLMS as foundation models trained on immense amounts of data, enabling them to understand and generate natural language and other types of content for various tasks. They are popular for tasks like content generation, language translation, code writing, summarization, and more. LLMs are accessible through interfaces like GPT-3, GPT-4, BERT, RoBERTa, and others, designed to mimic human-like text generation and understanding based on the extensive data they are trained on.\\n\\nCloudFare explains LLMS as machine learning models that use deep learning techniques to understand how characters, words, and sentences function together. Trained on large amounts of data, LLMs recognize patterns and relationships within language. They can be fine-tuned for specific tasks such as generating text, translating languages, or answering queries based on the data they have been trained on. However, the reliability of the information provided by LLMs depends on the quality of the data they have been trained on, and they can sometimes produce inaccurate or fake information. Additionally, LLMs can be vulnerable to security issues if not handled properly.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import Tool\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "#ChatGoogleGenerativeAI(google_api_key=api_key,model=\"gemini-1.5-flash-latest\", temperature=0.3)\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Retrieve the API key\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "#api_key = os.getenv(\"google_api_key\")\n",
    "\n",
    "if openai_api_key is None:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in environment variables\")\n",
    "from pydantic.v1 import BaseModel, Field\n",
    "class DocumentInput(BaseModel):\n",
    "    question: str = Field()\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "tools = []\n",
    "files = [\n",
    "    # https://abc.xyz/investor/static/pdf/2023Q1_alphabet_earnings_release.pdf\n",
    "    {\n",
    "        \"name\": \"Geeks_For_Geeks\",\n",
    "        \"path\": \"GFG.txt\",\n",
    "    },\n",
    "    # https://digitalassets.tesla.com/tesla-contents/image/upload/IR/TSLA-Q1-2023-Update\n",
    "    {\n",
    "        \"name\": \"CloudFare\",\n",
    "        \"path\": \"cf.txt\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"ibm\",\n",
    "        \"path\": \"ibm.txt\",\n",
    "    },\n",
    "    \n",
    "]\n",
    "\n",
    "for file in files:\n",
    "    loader = TextLoader(file[\"path\"],encoding = 'UTF-8')\n",
    "    pages = loader.load_and_split()\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    docs = text_splitter.split_documents(pages)\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    retriever = FAISS.from_documents(docs, embeddings).as_retriever()\n",
    "\n",
    "    # Wrap retrievers in a Tool\n",
    "    tools.append(\n",
    "        Tool(\n",
    "            args_schema=DocumentInput,\n",
    "            name=file[\"name\"],\n",
    "            description=f\"useful when you want to answer questions about {file['name']}\",\n",
    "            func=RetrievalQA.from_chain_type(llm=llm, retriever=retriever),\n",
    "        )\n",
    "    )\n",
    "\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "import os\n",
    "llm = ChatOpenAI(\n",
    "temperature=0.5,\n",
    "model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "print(llm)\n",
    "# llm=ChatGoogleGenerativeAI(google_api_key=api_key,model=\"gemini-1.5-flash-latest\", temperature=0.3)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    agent=AgentType.OPENAI_FUNCTIONS,\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "k=agent({\"input\": \"How Geeks for Geeks explained LLms as compare to ibm and cloudfare?\"})\n",
    "# prompt = hub.pull(\"hwchase17/react\")\n",
    "# agent = create_react_agent(llm, tools, prompt)\n",
    "# agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "# agent_executor.invoke({\"input\": \"what is LangChain?\"})\n",
    "\n",
    "# prompt = hub.pull(\"hwchase17/react\")\n",
    "# agent = create_react_agent(llm, tools, prompt)\n",
    "# agent_executor = AgentExecutor.from_agent_and_tools(agent = agent, tools=tools)\n",
    "# #agent.invoke({\"input\": \"How Geeks for Geeks explained LLms as compare to ibm and cloudfare?\"})\n",
    "# print(agent_executor)\n",
    "\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geeks for Geeks explains Large Language Models (LLMs) as advanced artificial intelligence algorithms that utilize neural network techniques with a large number of parameters to process and understand human languages or text. These models are trained on extensive datasets using self-supervised learning techniques, where they learn intricate patterns and relationships from diverse language data during training. LLMs consist of multiple layers and employ attention mechanisms like self-attention to capture dependencies and relationships in text sequences. They can perform tasks such as text generation, machine translation, summary writing, image generation from texts, machine coding, chatbots, and conversational AI.\n",
      "\n",
      "IBM describes LLMS as foundation models trained on immense amounts of data, enabling them to understand and generate natural language and other types of content for various tasks. They are popular for tasks like content generation, language translation, code writing, summarization, and more. LLMs are accessible through interfaces like GPT-3, GPT-4, BERT, RoBERTa, and others, designed to mimic human-like text generation and understanding based on the extensive data they are trained on.\n",
      "\n",
      "CloudFare explains LLMS as machine learning models that use deep learning techniques to understand how characters, words, and sentences function together. Trained on large amounts of data, LLMs recognize patterns and relationships within language. They can be fine-tuned for specific tasks such as generating text, translating languages, or answering queries based on the data they have been trained on. However, the reliability of the information provided by LLMs depends on the quality of the data they have been trained on, and they can sometimes produce inaccurate or fake information. Additionally, LLMs can be vulnerable to security issues if not handled properly.\n"
     ]
    }
   ],
   "source": [
    "print(k['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `CloudFare` with `{'question': 'Explain LLms of Cloudfare'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m{'query': 'Explain LLms of Cloudfare', 'result': 'Cloudflare offers services that allow developers to quickly start building Large Language Models (LLMs). Developers can use services like Vectorize, a globally distributed vector database, to query data stored in object storage or documents stored in Workers Key Value. By combining this with Cloudflare Workers AI, developers can experiment with building their own LLM applications. LLMs are based on machine learning, specifically deep learning, to understand and generate text responses. They can be used for tasks like generating text in response to prompts or questions. However, there are security concerns related to LLMs, such as potential vulnerabilities to malicious inputs and the exposure of confidential data.'}\u001b[0m\u001b[32;1m\u001b[1;3mCloudflare offers services that allow developers to quickly start building Large Language Models (LLMs). Developers can use services like Vectorize, a globally distributed vector database, to query data stored in object storage or documents stored in Workers Key Value. By combining this with Cloudflare Workers AI, developers can experiment with building their own LLM applications. LLMs are based on machine learning, specifically deep learning, to understand and generate text responses. They can be used for tasks like generating text in response to prompts or questions. However, there are security concerns related to LLMs, such as potential vulnerabilities to malicious inputs and the exposure of confidential data.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Explain LLms of Cloudfare',\n",
       " 'output': 'Cloudflare offers services that allow developers to quickly start building Large Language Models (LLMs). Developers can use services like Vectorize, a globally distributed vector database, to query data stored in object storage or documents stored in Workers Key Value. By combining this with Cloudflare Workers AI, developers can experiment with building their own LLM applications. LLMs are based on machine learning, specifically deep learning, to understand and generate text responses. They can be used for tasks like generating text in response to prompts or questions. However, there are security concerns related to LLMs, such as potential vulnerabilities to malicious inputs and the exposure of confidential data.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent({\"input\": \"Explain LLms of Cloudfare\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
